# @package _global_

defaults:
  - override /datamodule: synthie_400k
  - override /model: flan_t5_base
  - override /trainer: ddp
  - override /logger: wandb

train_split: "train"

# the parameters below will be merged with parameters from the default configurations set above
# this allows you to overwrite only a small/specific set of parameters
datamodule:
  batch_size: 2

  linearization_class_id: fully_expanded
  constrained_world: "genie_t5_tokenizeable"

  count_datapoints_with_unk_in_target: True
  verify_triplet_ordering: False


trainer:
  devices: 1
  accumulate_grad_batches: 40 # x bs x devices = 40 * 8 * 8 = 2560
  max_steps: 10000
  val_check_interval: ${mult_int:${.accumulate_grad_batches}, 80} # number of training steps between validation runs
  strategy: "ddp_find_unused_parameters_false"

model:
  optimizer:
    lr: 3.0e-04
    adam_eps: 1.0e-08
    weight_decay: 0.05
  scheduler:
    name: polynomial
    lr_end: 3.0e-05
    warmup_updates: 1000
    total_num_updates: ${trainer.max_steps}

# name of the run determines folder name in logs
run_name: "synthie_base_fe_400k"
